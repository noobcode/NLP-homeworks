{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from nltk.corpus import movie_reviews as mr\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "from itertools import chain\n",
    "\n",
    "test_plus_valid_perc = .2\n",
    "valid_of_test_perc = .5\n",
    "\n",
    "data = []\n",
    "# create a useful dictionary from each review\n",
    "for category in mr.categories():\n",
    "\n",
    "    if category == 'pos':\n",
    "        pretty_category_name = 'positive'\n",
    "    elif category == 'neg':\n",
    "        pretty_category_name = 'negative'\n",
    "\n",
    "    for fileid in mr.fileids(category):\n",
    "\n",
    "        review_words = mr.words(fileid)\n",
    "        review_text = ''\n",
    "        \n",
    "        for word in review_words:\n",
    "            review_text += ' ' + word\n",
    "\n",
    "        review_dictionary = {\n",
    "            'text': review_text,\n",
    "            'sentiment': pretty_category_name\n",
    "        }\n",
    "\n",
    "        data.append(review_dictionary)\n",
    "        \n",
    "# create a useful dictionary from each review\n",
    "train, test = train_test_split(data, test_size=test_plus_valid_perc)\n",
    "test, valid = train_test_split(test, test_size=valid_of_test_perc)\n",
    "\n",
    "def get_arrays(dictionaries):\n",
    "    x = []\n",
    "    y = []\n",
    "    for review in dictionaries:\n",
    "        x.append(review['text'])\n",
    "        y.append(1 if review['sentiment'] == 'positive' else 0)\n",
    "    return x, y\n",
    "\n",
    " # create simple train and test and validation x - y arrays   \n",
    "train_x, train_y = get_arrays(train) \n",
    "test_x, test_y = get_arrays(test) \n",
    "valid_x, valid_y = get_arrays(valid) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for 500 features\n",
      "accuracy score test: 77.00%\n",
      "accuracy score train: 86.69%\n",
      "accuracy score valid: 81.00%\n",
      "time: 6.47s\n",
      "--------------------------------------------------\n",
      "Result for 1000 features\n",
      "accuracy score test: 83.50%\n",
      "accuracy score train: 91.38%\n",
      "accuracy score valid: 83.50%\n",
      "time: 5.89s\n",
      "--------------------------------------------------\n",
      "Result for 1500 features\n",
      "accuracy score test: 85.50%\n",
      "accuracy score train: 93.81%\n",
      "accuracy score valid: 85.00%\n",
      "time: 5.73s\n",
      "--------------------------------------------------\n",
      "Result for 2000 features\n",
      "accuracy score test: 85.50%\n",
      "accuracy score train: 94.75%\n",
      "accuracy score valid: 85.50%\n",
      "time: 5.61s\n",
      "--------------------------------------------------\n",
      "Result for 2500 features\n",
      "accuracy score test: 85.50%\n",
      "accuracy score train: 95.25%\n",
      "accuracy score valid: 87.50%\n",
      "time: 5.55s\n",
      "--------------------------------------------------\n",
      "Result for 3000 features\n",
      "accuracy score test: 85.50%\n",
      "accuracy score train: 95.62%\n",
      "accuracy score valid: 85.50%\n",
      "time: 5.55s\n",
      "--------------------------------------------------\n",
      "Result for 3500 features\n",
      "accuracy score test: 85.00%\n",
      "accuracy score train: 96.00%\n",
      "accuracy score valid: 86.00%\n",
      "time: 5.59s\n",
      "--------------------------------------------------\n",
      "Result for 4000 features\n",
      "accuracy score test: 85.50%\n",
      "accuracy score train: 96.12%\n",
      "accuracy score valid: 87.50%\n",
      "time: 5.64s\n",
      "--------------------------------------------------\n",
      "Result for 4500 features\n",
      "accuracy score test: 86.00%\n",
      "accuracy score train: 96.00%\n",
      "accuracy score valid: 88.00%\n",
      "time: 5.78s\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def fit_and_analyze(pipeline, x_train, y_train, x_test, y_test, x_valid, y_valid):\n",
    "    t0 = time()\n",
    "    \n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred_test = sentiment_fit.predict(x_test)\n",
    "    y_pred_train = sentiment_fit.predict(x_train)\n",
    "    y_pred_valid = sentiment_fit.predict(x_valid)\n",
    "    \n",
    "    train_test_time = time() - t0\n",
    "    \n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_valid = accuracy_score(y_valid, y_pred_valid)\n",
    "    print (\"accuracy score test: {0:.2f}%\".format(accuracy_test*100))\n",
    "    print (\"accuracy score train: {0:.2f}%\".format(accuracy_train*100))\n",
    "    print (\"accuracy score valid: {0:.2f}%\".format(accuracy_valid*100))\n",
    "    print (\"time: {0:.2f}s\".format(train_test_time))\n",
    "    print (\"-\"*50)\n",
    "    return sentiment_fit \n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "tvec = TfidfVectorizer(min_df=2)\n",
    "\n",
    "ngram_size = 2\n",
    "features = range(500, 5000, 500)\n",
    "\n",
    "for numFeatures in features:\n",
    "    result = []\n",
    "    tvec.set_params(stop_words=stopwords.words('english'), max_features=numFeatures, ngram_range=(1, ngram_size))\n",
    "    checker_pipeline = Pipeline([\n",
    "        ('vectorizer', tvec),\n",
    "        ('classifier', lr)\n",
    "    ])\n",
    "    print (\"Result for {} features\".format(numFeatures))\n",
    "    fit_and_analyze(checker_pipeline, train_x, train_y, test_x, test_y, valid_x, valid_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
